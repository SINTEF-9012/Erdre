profile:
    # dataset: Name of data set, which is the name of the subfolder in which the data
    # files resides: 'assets/data/raw/[dataset]/. If empty, put data files in
    # 'assets/data/raw/'.
    dataset: 

clean:
    # target: Name of target variable.
    target: 

    # combine_files: Whether to combine the data from all files into one file
    # after cleaning.
    #
    # Sometimes it is desirable to not combine the data into a single file,
    # for example when:
    # - Some specific files contain data that should be reserved for the test set.
    # - We are going to use sequences of data points as input samples, and do
    #   not want sequences to overlap across files.
    #
    combine_files: False

    # percentage_zeros_threshold: If the fraction of zeros in a column is
    # larger than this threshold, the column is removed. If this parameter is
    # set to 1.0, we will only remove the columns that solely consists of
    # zeros.
    percentage_zeros_threshold: 0.5

    # correlation_metric: Which metric to measure correlation by. Choose from:
    # - pearson
    # - spearman
    # - phi_k
    # - cramers
    correlation_metric: pearson

    # input_max_correlation_threshold: If the correlation between two variables are
    # higher than this threshold, one of them will be removed. If the threshold
    # is set to 1.0, no variables will be removed.
    input_max_correlation_threshold: 1.0

featurize:
    # features: Which features to use from the data set. If empty, all columns
    # from input files are used (except those that are removed during
    # cleaning).
    features:
        # - feature1
        # - feature2

    # target_min_correlation_threshold: Minimum correlation between target and
    # an input feature to include the feature in the model. If set to 0.0, no
    # features will be removed based on correlation.
    target_min_correlation_threshold: 0.0

split:
    # train_split: Fraction of data set to use for training.
    train_split: 0.5

    # calibrate_split: Fraction of data set to use for calibration. If set to
    # 0, no conformal prediction is performed.
    calibrate_split: 0.3

scale:
    # Current available scaling methods are:
    # - standard
    # - minmax
    input: standard
    output: standard

sequentialize:
    # History window sample size
    hist_size: 10
    # Currently, a target_size greater than 1 is not supported if calibrate_split > 0
    target_size: 1

train:
    # net: Which type of neural network to use. Choose from:
    # - dnn (dense neural network)
    # - cnn (convolutional neural network
    net: cnn

    # n_epochs: Number of epochs to perform during training. If early_stopping
    # is set to True, training may be stopped before n_epochs is reached.
    n_epochs: 100

    batch_size: 128
    
    # kernel_size: Only applicable for CNN
    kernel_size: 3

    # early_stopping: Stop training if validation loss does not improve after
    # [patience] number of epochs.
    early_stopping: True

    # patience: The number of epochs to wait for validation loss to improve,
    # before stopping training early.
    patience: 40

evaluate:
